# OVERVIEW

<!--toc:start-->

- [OVERVIEW](#overview)
- [about Nerf](#about-nerf)
  - [0. 専門用語](#0-専門用語)
  - [1. はじめに](#1-はじめに)
  - [2. 訓練過程](#2-訓練過程)
  - [3. 推論過程](#3-推論過程)
  - [4. カメラの内部パラメータ](#4-カメラの内部パラメータ)
    - [カメラ座標系とワールド座標系](#カメラ座標系とワールド座標系)
    - [画像同士のマッチングについて](#画像同士のマッチングについて)
    - [カメラ外部パラメータの推定](#カメラ外部パラメータの推定)
  - [5. NeRFのパラメータ](#5-nerfのパラメータ)
    - [AABB](#aabb)
  - [Memo](#memo)
  <!--toc:end-->

# about Nerf

> [Nerfを1から](https://kentapt.hatenablog.com/entry/2023/07/30/203604)  
> [Nerf 論文](https://arxiv.org/pdf/2003.08934.pdf)

## 0. 専門用語

- 推論
  テストと同様の意味で使用される．

## 1. はじめに

Nerf(Neural Raduiance Field) とは，複雑なシーンに対して，任意の視点からの3次元的なシーンを画像から再構成する技術．  
Nerfの入力は任意の方向の高専と対象とするその光線上の点の座標である．そして，Nerfのアルゴリズムにそれらを取得すると，その任意の点の色とその密度を出力することができる．  
もし，その指定した点に何もない空間を指定した場合は，その密度は０に近づく．一方で，その指定した点が対象の物体の表面にあると，その密度は1に近づく．

1. 複数のカメラにて対象物を異なる角度から撮影し，複数の画像を取得する．その際，入力として位置+角度情報(x, y, z, θ, φ)の５次元のデータを取得することになる．
2. 得られた5次元のデータをニューラルネットワークにかけ，3Dモデルを生成する．
3. 生成された3Dモデルを用いて，任意の視点からの画像を生成する．

## 2. 訓練過程

カメラキャリブレーションを行い，焦点距離やレンズの歪みの情報などのパラメータがわかっているカメラを用意する．
複数の位置・角度から撮影を行い，その位置・角度情報とともに学習データを作成する．

NeRFで利用するニューラルネットワークの訓練を行う．

1. 取得したデータ画像全てを利用して訓練する．
2. ニューラルネットワークの訓練のために，画像から複数の画素をピックアップする．
3. そのピックアップしたそれぞれのがその光線の向きを考え，その仮想的な光線上の複数の点(下の例では，7点を想定)を得る．
4. その光線上の複数の点に対して，色情報と密度を求める．
5. その光線にそって，色と密度(透明度みたいなもの??)を積算する. そして，その光線がそのカメラから発せられた場合，その画素で得られる色を算出する．
6. 実際のカメラ画像のその画素のそのがその色情報を取り出し，5. で計算した値との差分(二乗誤差)を計算する．
7. 3.~6. を繰り返し，この訓練の1つのステップ(Mini Batch)とする．
8. 7.で得られたMini Batchに対する誤差を最小化するために逆誤差伝播法にて重みやバイアスなどの最適化を行う．
9. 設定した回数だけ学習を行い，NeRFのためのニューラルネットワークを計算する．

<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/k/kentaPt/20230730/20230730182718.png" width=500>

## 3. 推論過程

任意の位置・角度からの画像を生成する.

1. カメラの内部パラメータを設定した上で，新たなシーンを生成するための仮想的なカメラの位置と向きを設定する．
2. 焦点距離などの(仮想的な)カメラの内部パラメータを利用して，各カメラの画素とカメラの中心を結ぶ光線を生成する．
3. 2.で生成した光線上で，複数の点における色，密度情報を得る．
4. 3.で得られた情報を利用して，その光線上の色情報を積算し，画素へのレンダリングを行う．
5. 2.~5.を繰り返し，複数のカメラ全てに対して同様の処理を行うことで，新たなシーンを生成する．

## 4. カメラの内部パラメータ

カメラの内部パラメータには，焦点距離，光学的距離，剪断係数が含まれる．

f: 焦点距離, c: 光学的中心, s: 剪断係数

$$
R =
\left[
\begin{matrix} f_{x} & s & c_{x} \\ 0 & f_{y} & c_{y} \\ 0 & 0 & 1
\end{matrix}
\right]
$$

以下は，カメラキャリブレーションの様子．
<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/k/kentaPt/20230730/20230730183258.png" width=500>

詳しくは，以下を参照．

> [カメラ内部パラメータについて](https://jp.mathworks.com/help/vision/ug/camera-calibration.html)

### カメラ座標系とワールド座標系

ここで，カメラ座標系とワールド座標系について説明する．
以下の図のように，カメラの光学的中心を原点として，Z軸をカメラの光学中心に一致させたものをカメラ座標系とする．一方で，シーンに固定された一意に定まる座標系をワールド座標系という??．

<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/k/kentaPt/20230730/20230730184141.png" width=500>

カメラ座標と，ワールド座標は，$R$と$t$を用いて，以下のように表現できる．

$$
R =
\left[
\begin{matrix} r_{11} & r_{12} & r_{13} \\ r_{21} & r_{22} & r_{23} \\ r_{31} & r_{32} & r_{33} \end{matrix}
\right]
$$

$$
t =
\left[
\begin{matrix} t_1 \\ t_2 \\ t_3 \end{matrix}
\right]
$$

### 画像同士のマッチングについて

前章では，対象物を複数の角度から撮影した後に，それぞれのカメラの位置と向きを求めることを目標としていた．  
それには，複数の画像をうまく繋ぎ合わせる必要がある．例えば，ある物体を撮影し，少し横にずれた状態で再び画像を取得したとする．  
画像中の物体から共通した部分を見つけて，対応づけることが重要である．

例えば，以下の画像の例を考える．  
異なる角度から同じコップを撮影している．
コップの絵柄などの，特徴的な箇所を見つけて，それらを目印にそれぞれの対応関係を求め，その対応関係から，カメラの位置を推定している．

<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/k/kentaPt/20230730/20230730185008.png" width=500>

特徴量を抽出アルゴリズムには，SHIFTやSURFがある．

### カメラ外部パラメータの推定

特徴量抽出アルゴリズムによって，二つの画像間で，複数の特徴量のペアが求まったとする．  
一つのカメラの位置を基準とし，それをワールド座標系とみなすことで，2つのカメラの位置と特徴量の位置の関係を9つの未知数を持って紐付けることができる.  
9つとは，もう片方のカメラの位置の6自由度??と，特徴点情報の3自由度である．  
もう一つのカメラの相対的な位置は，回転行列と並行移動のベクトルで表現することができる．

$$
\left[
\begin{matrix} X \\ Y \\ Z \end{matrix}
\right]
= R
\left[
\begin{matrix} X_w \\ Y_w \\ Z_w \end{matrix}
\right]
+ t
$$

$$
R =
\left[
\begin{matrix} r_{11} & r_{12} & r_{13} \\ r_{21} & r_{22} & r_{23} \\ r_{31} & r_{32} & r_{33} \end{matrix}
\right]
$$

$$
t =
\left[
\begin{matrix} t_1 \\ t_2 \\ t_3 \end{matrix}
\right]
$$

## 5. NeRFのパラメータ

### AABB

コンピュータはどの点がオブジェクトの内側にあって，どの点が外側にあるのか知る必要がある．  
これを実現する1つの方法が **AABB(Axis-Aligned Bounding Box)** である．

Axis-Aligned Bounding Boxとは，その名の通り，各軸に平行な直方体のことである．  
この長方形は，点群の幾何学的な形状を表すようなもの．  
例えるならば，パワーポイントで点群を短形選択して，グループ化する感じ．  
これがないと，NeRFで得られた点群を正しくスケールできなくなる．

<img src="https://radiancefields.com/wp-content/uploads/2023/04/B05887_7_5.jpg.webp" width=500>

AABBは，1, 2, 4, 8, 16, 32, ... , $2^n$のような2の累乗の数で表現される．  
累乗の数が大きくなるに連れて，占有格子が2x2x2, 4x4x4, 8x8x8, ...となり，VRAMの消費が大きくなる．

AABBは，x, y, z座標が最も小さい点(これを点Aと呼ぶ)と，x, y, z座標が最も大きい点(これを点Bと呼ぶ)の2点で定義される．  
つまり，AABBはNeRFの被写体の**高さ，幅，奥行き**である．

<img src="https://radiancefields.com/wp-content/uploads/2023/04/0000612717.png.webp" width=500>

NeRFがシーンをレンダリングする際に，まず画像の各ビクセルを通過する一連の視線を生成する．  
その後，アルゴリズムはこれらの光線に沿って点をサンプリングし，ニューラルネットワークに問い合わせて各点の輝度と体積密度を計算する．  
このプロセスを最適化するために，3D空間をより小さな領域(ボクセル)に分割するAABBが採用される．  
各ボクセルには，バンディングボックスが関連つけられr，視線がシーンと交差する領域を特定するのに役立つ．  
交差が起きるボクセルのみに焦点を当てることで，ネットワーククエリの数が大幅に削減され，効率よくレンダリング処理することができる．

ユースケースによって，適したAABBのサイズは異なる．

盆栽のような小さなオブジェクトの場合は，AABBのサイズは小さくなる．  
一方，建物のようなオブジェクトでは，AABBのサイズは大きくなる．

以下は，**AABB=16**  
<img src="./.img/AABB16.gif" width=500>

以下は，**AABB=128**  
<img src="./.img/AABB128.gif" width=500>

上のgifからわかるように，AABBサイズが大きい場合に端の位置が遠くなっている．  
また，AABBサイズの方が小さい場合に，対象の解像度も高くなっている．

カメラの絞りと近い挙動らしいが，カメラ知らん．  
以下は，カメラの絞りの例．  
<img src="https://radiancefields.com/wp-content/uploads/2023/04/Screenshot-2023-04-10-at-1.28.53-PM-1024x258.png.webp" width=500>

Luna AIのこれがAABBを決める操作になっているみたい．  
<img src="https://radiancefields.com/wp-content/uploads/2023/04/IMG_4641-edited.jpg.webp" width=300>

**盆栽のサイズに依るが，AABBは8か16で良さそう．**

> [参考: What is an AABB](https://radiancefields.com/what-is-a-aabb-for-nerfs/)

??AABBの直方体は，どのようにして位置が決まるの? 平均とか求めてんのか？??

## Memo

1. 訓練と推論の流れ
   ５次元の訓練データを用いて，それらによって学習されたモデルを用いて，推論を行う．推論の結果を評価するには，与えてない５次元訓練データを用いて，そのモデルから得られたレンダリング画像と実際の画像を比較する？
   -> というより，全て訓練データにしてその中で，点群を最適化する．

2. レンズに依らないか？ appleでは，レンズの品番であらかじめパラメーターを選定しているらしい．
   レンズの歪みなどをcolmapは考慮しているのか？

3. シーンとは，3D空間内に配置された一連のオブジェクト，光源，カメラ，そしてそれらが相互に関連しあって，作り出す環境や設定のこをさす．

4. ~~全てを3dとするのには限界があるのでは？テクスチャとして処理するNeRFもあるのか？~~

5. どうやって，NeRFで生成した点群を系統樹分析するのか？
   -> 点群の種類でクラスタリングすることができると思う．
   例えば，種類のクラスに木，葉, 空気，(土，入れ物, その他)として分類する．
   そして，その木のみを抽出して，木だけのボーンモデルから，系統樹分析を行う.
   試作品てこともあって，一つの品種だけでいいと思う(真柏だけとか)．
